"""Metrics middleware for Prometheus."""

from __future__ import annotations

import time
from collections import defaultdict
from datetime import datetime
from typing import Any

from fastapi import Request, Response
from fastapi.responses import Response as FastAPIResponse
from prometheus_client import CONTENT_TYPE_LATEST, Counter, Gauge, Histogram, Info, generate_latest

# Request metrics
http_requests_total = Counter(
    "aicdn_http_requests_total", "Total HTTP requests", ["method", "endpoint", "status"]
)

http_request_duration_seconds = Histogram(
    "aicdn_http_request_duration_seconds",
    "HTTP request duration in seconds",
    ["method", "endpoint"],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.5, 5.0, 10.0],
)

http_request_size_bytes = Histogram(
    "aicdn_http_request_size_bytes", "HTTP request size in bytes", ["method", "endpoint"]
)

http_response_size_bytes = Histogram(
    "aicdn_http_response_size_bytes", "HTTP response size in bytes", ["method", "endpoint"]
)

# LLM metrics
llm_requests_total = Counter(
    "aicdn_llm_requests_total", "Total LLM requests", ["operation", "status"]
)

llm_tokens_generated = Counter(
    "aicdn_llm_tokens_generated_total", "Total tokens generated by LLM", ["model"]
)

llm_generation_duration_seconds = Histogram(
    "aicdn_llm_generation_duration_seconds",
    "LLM generation duration in seconds",
    ["model", "operation"],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0],
)

# Blueprint metrics
blueprint_operations_total = Counter(
    "aicdn_blueprint_operations_total", "Total blueprint operations", ["operation", "status"]
)

blueprint_resources_count = Histogram(
    "aicdn_blueprint_resources_count",
    "Number of resources in blueprints",
    buckets=[1, 5, 10, 20, 50, 100],
)

# Deployment metrics
deployment_operations_total = Counter(
    "aicdn_deployment_operations_total", "Total deployment operations", ["engine", "status"]
)

deployment_duration_seconds = Histogram(
    "aicdn_deployment_duration_seconds",
    "Deployment duration in seconds",
    ["engine"],
    buckets=[10, 30, 60, 180, 300, 600, 1800, 3600],
)

# Rate limiting metrics
rate_limit_hits_total = Counter(
    "aicdn_rate_limit_hits_total", "Total rate limit hits", ["endpoint"]
)

# Tool execution metrics
tool_executions_total = Counter(
    "aicdn_tool_executions_total", "Total tool executions", ["tool_name", "status"]
)

tool_execution_duration_seconds = Histogram(
    "aicdn_tool_execution_duration_seconds",
    "Tool execution duration in seconds",
    ["tool_name"],
    buckets=[0.01, 0.1, 0.5, 1.0, 5.0, 10.0],
)

# System metrics
active_connections = Gauge("aicdn_active_connections", "Number of active connections")

database_connections = Gauge(
    "aicdn_database_connections", "Number of database connections", ["state"]
)

# Application info
app_info = Info("aicdn_app", "Application information")


class MetricsCollector:
    """
    Centralized metrics collector for ALMA.

    Provides convenience methods for recording metrics.
    """

    def __init__(self):
        """Initialize metrics collector."""
        self.start_time = time.time()
        self.custom_metrics: dict[str, Any] = defaultdict(int)

    def record_http_request(
        self,
        method: str,
        endpoint: str,
        status: int,
        duration: float,
        request_size: int = 0,
        response_size: int = 0,
    ) -> None:
        """
        Record HTTP request metrics.

        Args:
            method: HTTP method
            endpoint: Endpoint path
            status: Response status code
            duration: Request duration in seconds
            request_size: Request size in bytes
            response_size: Response size in bytes
        """
        http_requests_total.labels(method=method, endpoint=endpoint, status=str(status)).inc()

        http_request_duration_seconds.labels(method=method, endpoint=endpoint).observe(duration)

        if request_size > 0:
            http_request_size_bytes.labels(method=method, endpoint=endpoint).observe(request_size)

        if response_size > 0:
            http_response_size_bytes.labels(method=method, endpoint=endpoint).observe(response_size)

    def record_llm_request(
        self, operation: str, model: str, duration: float, tokens: int = 0, status: str = "success"
    ) -> None:
        """
        Record LLM request metrics.

        Args:
            operation: Operation type
            model: Model name
            duration: Generation duration
            tokens: Tokens generated
            status: Operation status
        """
        llm_requests_total.labels(operation=operation, status=status).inc()

        llm_generation_duration_seconds.labels(model=model, operation=operation).observe(duration)

        if tokens > 0:
            llm_tokens_generated.labels(model=model).inc(tokens)

    def record_blueprint_operation(
        self, operation: str, status: str = "success", resource_count: int = 0
    ) -> None:
        """
        Record blueprint operation metrics.

        Args:
            operation: Operation type (create, validate, deploy, etc.)
            status: Operation status
            resource_count: Number of resources in blueprint
        """
        blueprint_operations_total.labels(operation=operation, status=status).inc()

        if resource_count > 0:
            blueprint_resources_count.observe(resource_count)

    def record_deployment(self, engine: str, duration: float, status: str = "success") -> None:
        """
        Record deployment metrics.

        Args:
            engine: Engine name
            duration: Deployment duration
            status: Deployment status
        """
        deployment_operations_total.labels(engine=engine, status=status).inc()

        deployment_duration_seconds.labels(engine=engine).observe(duration)

    def record_rate_limit(self, endpoint: str) -> None:
        """
        Record rate limit hit.

        Args:
            endpoint: Endpoint that was rate limited
        """
        rate_limit_hits_total.labels(endpoint=endpoint).inc()

    def record_tool_execution(
        self, tool_name: str, duration: float, status: str = "success"
    ) -> None:
        """
        Record tool execution metrics.

        Args:
            tool_name: Name of executed tool
            duration: Execution duration
            status: Execution status
        """
        tool_executions_total.labels(tool_name=tool_name, status=status).inc()

        tool_execution_duration_seconds.labels(tool_name=tool_name).observe(duration)

    def update_connections(self, active: int) -> None:
        """
        Update active connections gauge.

        Args:
            active: Number of active connections
        """
        active_connections.set(active)

    def update_database_connections(self, active: int, idle: int) -> None:
        """
        Update database connection gauges.

        Args:
            active: Active connections
            idle: Idle connections
        """
        database_connections.labels(state="active").set(active)
        database_connections.labels(state="idle").set(idle)

    def get_uptime(self) -> float:
        """
        Get application uptime in seconds.

        Returns:
            Uptime in seconds
        """
        return time.time() - self.start_time

    def get_summary(self) -> dict[str, Any]:
        """
        Get metrics summary.

        Returns:
            Metrics summary dictionary
        """
        return {
            "uptime_seconds": self.get_uptime(),
            "timestamp": datetime.utcnow().isoformat(),
            "custom_metrics": dict(self.custom_metrics),
        }


# Global metrics collector instance
_metrics_collector: MetricsCollector | None = None


def get_metrics_collector() -> MetricsCollector:
    """
    Get global metrics collector instance.

    Returns:
        Metrics collector
    """
    global _metrics_collector

    if _metrics_collector is None:
        _metrics_collector = MetricsCollector()

        # Set application info
        app_info.info(
            {"version": "0.1.0", "name": "ALMA", "description": "Infrastructure as Conversation"}
        )

    return _metrics_collector


async def metrics_middleware(request: Request, call_next) -> Response:
    """
    Middleware to collect HTTP request metrics.

    Args:
        request: FastAPI request
        call_next: Next middleware/handler

    Returns:
        Response
    """
    # Skip metrics for metrics endpoint itself
    if request.url.path == "/metrics":
        return await call_next(request)

    start_time = time.time()

    # Get request size
    request_size = 0
    if request.headers.get("content-length"):
        try:
            request_size = int(request.headers["content-length"])
        except (KeyError, ValueError):
            pass

    # Process request
    response = await call_next(request)

    # Calculate duration
    duration = time.time() - start_time

    # Get response size
    response_size = 0
    if hasattr(response, "headers") and response.headers.get("content-length"):
        try:
            response_size = int(response.headers["content-length"])
        except (KeyError, ValueError):
            pass

    # Simplify endpoint for metrics (remove IDs)
    endpoint = request.url.path
    for segment in endpoint.split("/"):
        if segment.isdigit():
            endpoint = endpoint.replace(f"/{segment}", "/:id")

    # Record metrics
    collector = get_metrics_collector()
    collector.record_http_request(
        method=request.method,
        endpoint=endpoint,
        status=response.status_code,
        duration=duration,
        request_size=request_size,
        response_size=response_size,
    )

    return response


def get_prometheus_metrics() -> Response:
    """
    Get Prometheus-formatted metrics.

    Returns:
        Prometheus metrics response
    """
    metrics_data = generate_latest()
    return FastAPIResponse(content=metrics_data, media_type=CONTENT_TYPE_LATEST)
